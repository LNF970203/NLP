{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b27e19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import nltk\n",
    "from rake_nltk import Rake\n",
    "import re\n",
    "import en_core_web_sm\n",
    "from collections import Counter\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78642edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2fdc9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text = \"When it comes to evaluating the performance of keyword extractors, you can use some of the standard metrics in machine learning: accuracy, precision, recall, and F1 score. However, these metrics don’t reflect partial matches; they only consider the perfect match between an extracted segment and the correct prediction for that tag.Fortunately, there are some other metrics capable of capturing partial matches. An example of this is ROUGE.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bee7e0",
   "metadata": {},
   "source": [
    "### 1. Rake - NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fd976cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the object\n",
    "r = Rake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69fdf829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9.0, 'reflect partial matches'),\n",
       " (9.0, 'capturing partial matches'),\n",
       " (4.0, 'perfect match'),\n",
       " (4.0, 'machine learning'),\n",
       " (4.0, 'keyword extractors'),\n",
       " (4.0, 'f1 score'),\n",
       " (4.0, 'extracted segment'),\n",
       " (4.0, 'correct prediction'),\n",
       " (3.666666666666667, 'standard metrics'),\n",
       " (3.666666666666667, 'metrics capable'),\n",
       " (1.6666666666666667, 'metrics'),\n",
       " (1.0, '’'),\n",
       " (1.0, 'use'),\n",
       " (1.0, 'tag'),\n",
       " (1.0, 'rouge'),\n",
       " (1.0, 'recall'),\n",
       " (1.0, 'precision'),\n",
       " (1.0, 'performance'),\n",
       " (1.0, 'however'),\n",
       " (1.0, 'fortunately'),\n",
       " (1.0, 'example'),\n",
       " (1.0, 'evaluating'),\n",
       " (1.0, 'consider'),\n",
       " (1.0, 'comes'),\n",
       " (1.0, 'accuracy')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.extract_keywords_from_text(my_text)\n",
    "ranked_list = r.get_ranked_phrases_with_scores()\n",
    "ranked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d641bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for text1 in ranked_list:\n",
    "    keyword = text1[1].split()\n",
    "    keyword_update = \" \".join(keyword[:2])\n",
    "    text.append(keyword_update)\n",
    "    if(len(text) > 5):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e357105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reflect partial, capturing partial, perfect match, machine learning, keyword extractors, f1 score\n"
     ]
    }
   ],
   "source": [
    "print(*text, sep = \", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa7e78",
   "metadata": {},
   "source": [
    "### 2. Using Spacy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d60d8856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotwords(text):\n",
    "    results = []\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN']\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if (token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            continue\n",
    "        if (token.pos_ in pos_tag):\n",
    "            results.append(token)\n",
    "    \n",
    "    return list(set(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc42effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text2 = \"When it comes to evaluating the performance of keyword extractors, you can use some of the standard metrics in machine learning: accuracy, precision, recall, and F1 score. However, these metrics don’t reflect partial matches. they only consider the perfect match between an extracted segment and the correct prediction for that tag.Fortunately, there are some other metrics capable of capturing partial matches. An example of this is ROUGE.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b41f0999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics\n",
      "match\n",
      "keyword\n",
      "capable\n",
      "partial\n",
      "machine\n",
      "standard\n",
      "accuracy\n",
      "matches\n",
      "perfect\n"
     ]
    }
   ],
   "source": [
    "hotwords = get_hotwords(my_text2)\n",
    "most_commonm_list = Counter(hotwords).most_common(10)\n",
    "for item in most_commonm_list:\n",
    "    print(item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b60f91",
   "metadata": {},
   "source": [
    "## Keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8ebf99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "        Supervised learning is the machine learning task of learning a function that\n",
    "         maps an input to an output based on example input-output pairs. It infers a\n",
    "         function from labeled training data consisting of a set of training examples.\n",
    "         In supervised learning, each example is a pair consisting of an input object\n",
    "         (typically a vector) and a desired output value (also called the supervisory signal). \n",
    "         A supervised learning algorithm analyzes the training data and produces an inferred function, \n",
    "         which can be used for mapping new examples. An optimal scenario will allow for the \n",
    "         algorithm to correctly determine the class labels for unseen instances. This requires \n",
    "         the learning algorithm to generalize from the training data to unseen situations in a \n",
    "         'reasonable' way (see inductive bias).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8629dc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised learning\n"
     ]
    }
   ],
   "source": [
    "#calling the objects\n",
    "kw_model = KeyBERT()\n",
    "key_words = kw_model.extract_keywords(doc, keyphrase_ngram_range=(2,2), top_n=2)\n",
    "print(key_words[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c4e886",
   "metadata": {},
   "source": [
    "- keyphrase_ngram_range attribute specifies the number of words to be in the key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29008496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Nature is important"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "n = 'Nature'\n",
    "check = \" Nature is important\"\n",
    "w1 = nlp(n)\n",
    "w2 = nlp(check)\n",
    "w2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d84d37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nature"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b322f7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Nature is important"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a612399d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-83685a01db20>:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  w1.similarity(w2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25014076470795077"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.similarity(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf2412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
